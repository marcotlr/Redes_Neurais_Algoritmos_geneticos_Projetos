{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6b95101-9cbc-4fa8-a9ba-7e1690f47e0b",
   "metadata": {},
   "source": [
    "# Treinando uma rede neural com pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8020d147",
   "metadata": {},
   "source": [
    "# Introdução\n",
    "\n",
    "O processo de treinamento de uma rede neural costuma envolver a otimização iterativa dos pesos até que a função de custo se estabilize ou até um número máximo de épocas seja alcançado. No entanto, treinar por muitas épocas pode levar a **overfitting**—quando o modelo começa a ajustar-se demais aos ruídos dos dados de treinamento e perde capacidade de generalização nos exemplos novos. Uma estratégia simples e eficaz para contornar esse problema é a **Parada Antecipada (Early Stopping)**, que interrompe o treino tão logo a performance em um conjunto de validação deixe de melhorar.\n",
    "\n",
    "Neste notebook implementamos o Early Stopping em uma rede neural feita no Pytorch, aproveitando o mecanismo de `torch.nn` e `torch.optim`.  \n",
    "\n",
    "Em ambos os casos, monitoramos a **loss** no conjunto de validação a cada época, salvamos o melhor estado de parâmetros e interrompemos o treino quando não houver melhora após um número fixo de épocas (patience). Ao final, comparamos as curvas de treinamento e validação, exibimos o ponto de parada e avaliamos o impacto do Early Stopping na capacidade de generalização do modelo.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13eae94c-96c0-4f39-9bb4-30d58cd93601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "91262595",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_dados_entrada, neuronios_c1, neuronios_c2, num_targets):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.camadas = nn.Sequential(\n",
    "            nn.Linear(num_dados_entrada, neuronios_c1),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(neuronios_c1, neuronios_c2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(neuronios_c2, num_targets),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.camadas(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "11f52abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Heart rate</th>\n",
       "      <th>Systolic blood pressure</th>\n",
       "      <th>Diastolic blood pressure</th>\n",
       "      <th>Blood sugar</th>\n",
       "      <th>CK-MB</th>\n",
       "      <th>Troponin</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>160</td>\n",
       "      <td>83</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.012</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>98</td>\n",
       "      <td>46</td>\n",
       "      <td>296.0</td>\n",
       "      <td>6.75</td>\n",
       "      <td>1.060</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>160</td>\n",
       "      <td>77</td>\n",
       "      <td>270.0</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.003</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>120</td>\n",
       "      <td>55</td>\n",
       "      <td>270.0</td>\n",
       "      <td>13.87</td>\n",
       "      <td>0.122</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>112</td>\n",
       "      <td>65</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.003</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>122</td>\n",
       "      <td>67</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.006</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>125</td>\n",
       "      <td>55</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.172</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>168</td>\n",
       "      <td>104</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.24</td>\n",
       "      <td>4.250</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>117</td>\n",
       "      <td>68</td>\n",
       "      <td>443.0</td>\n",
       "      <td>5.80</td>\n",
       "      <td>0.359</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>157</td>\n",
       "      <td>79</td>\n",
       "      <td>134.0</td>\n",
       "      <td>50.89</td>\n",
       "      <td>1.770</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1319 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Gender  Heart rate  Systolic blood pressure  \\\n",
       "0      64       1          66                      160   \n",
       "1      21       1          94                       98   \n",
       "2      55       1          64                      160   \n",
       "3      64       1          70                      120   \n",
       "4      55       1          64                      112   \n",
       "...   ...     ...         ...                      ...   \n",
       "1314   44       1          94                      122   \n",
       "1315   66       1          84                      125   \n",
       "1316   45       1          85                      168   \n",
       "1317   54       1          58                      117   \n",
       "1318   51       1          94                      157   \n",
       "\n",
       "      Diastolic blood pressure  Blood sugar  CK-MB  Troponin    Result  \n",
       "0                           83        160.0   1.80     0.012  negative  \n",
       "1                           46        296.0   6.75     1.060  positive  \n",
       "2                           77        270.0   1.99     0.003  negative  \n",
       "3                           55        270.0  13.87     0.122  positive  \n",
       "4                           65        300.0   1.08     0.003  negative  \n",
       "...                        ...          ...    ...       ...       ...  \n",
       "1314                        67        204.0   1.63     0.006  negative  \n",
       "1315                        55        149.0   1.33     0.172  positive  \n",
       "1316                       104         96.0   1.24     4.250  positive  \n",
       "1317                        68        443.0   5.80     0.359  positive  \n",
       "1318                        79        134.0  50.89     1.770  positive  \n",
       "\n",
       "[1319 rows x 9 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"C:/Users/marco24038/OneDrive - ILUM ESCOLA DE CIÊNCIA/Redes Neurais e Algoritmos Genéticos/Medicaldataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3e0d8010",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Blood sugar\", \"Result\", \"Gender\"])\n",
    "y = df[\"Blood sugar\"].values.reshape(-1, 1)\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "aa37d1dd-b051-4ea8-999f-5e27d6ff0b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.29050602e-02],\n",
       "       [-7.37248828e-01],\n",
       "       [-4.92186322e-01],\n",
       "       [-1.92665481e-01],\n",
       "       [-6.41946742e-01],\n",
       "       [ 1.88542862e-01],\n",
       "       [-6.41946742e-01],\n",
       "       [-6.41946742e-01],\n",
       "       [-7.78092579e-01],\n",
       "       [-8.87009248e-01],\n",
       "       [ 3.74194920e+00],\n",
       "       [-5.19415489e-01],\n",
       "       [ 8.69272046e-01],\n",
       "       [ 1.07349080e+00],\n",
       "       [-5.19415489e-01],\n",
       "       [-4.92186322e-01],\n",
       "       [-5.60259240e-01],\n",
       "       [-6.28332158e-01],\n",
       "       [ 5.36208466e+00],\n",
       "       [ 2.56615781e-01],\n",
       "       [-4.10498820e-01],\n",
       "       [-5.33030073e-01],\n",
       "       [ 3.33351169e+00],\n",
       "       [ 6.78667875e-01],\n",
       "       [-6.41946742e-01],\n",
       "       [-1.38207146e-01],\n",
       "       [-7.50863412e-01],\n",
       "       [-5.87488407e-01],\n",
       "       [-6.41946742e-01],\n",
       "       [-7.50863412e-01],\n",
       "       [-6.14717575e-01],\n",
       "       [-5.19415489e-01],\n",
       "       [-6.82790493e-01],\n",
       "       [-4.10498820e-01],\n",
       "       [-2.06130916e-03],\n",
       "       [ 3.79147034e-01],\n",
       "       [-4.37727987e-01],\n",
       "       [-6.96405077e-01],\n",
       "       [-7.23634244e-01],\n",
       "       [-5.46644656e-01],\n",
       "       [-3.01582150e-01],\n",
       "       [ 1.00541788e+00],\n",
       "       [ 6.78667875e-01],\n",
       "       [ 5.28907454e-01],\n",
       "       [-7.37248828e-01],\n",
       "       [ 9.37344965e-01],\n",
       "       [-5.19415489e-01],\n",
       "       [-2.33509232e-01],\n",
       "       [-4.64957154e-01],\n",
       "       [ 6.92282459e-01],\n",
       "       [-7.37248828e-01],\n",
       "       [-8.37488112e-02],\n",
       "       [-4.51342571e-01],\n",
       "       [-6.96405077e-01],\n",
       "       [-5.60259240e-01],\n",
       "       [-3.42425901e-01],\n",
       "       [-7.23634244e-01],\n",
       "       [ 3.64664712e+00],\n",
       "       [-7.50863412e-01],\n",
       "       [-2.92904765e-02],\n",
       "       [ 1.25048039e+00],\n",
       "       [ 3.24688699e-01],\n",
       "       [-7.01342276e-02],\n",
       "       [ 3.90532421e+00],\n",
       "       [ 6.51438708e-01],\n",
       "       [ 9.32407766e-02],\n",
       "       [-6.55561326e-01],\n",
       "       [-6.55561326e-01],\n",
       "       [ 7.19511626e-01],\n",
       "       [-8.18936330e-01],\n",
       "       [-2.92904765e-02],\n",
       "       [-6.14717575e-01],\n",
       "       [-7.64477995e-01],\n",
       "       [-3.83269652e-01],\n",
       "       [-6.82790493e-01],\n",
       "       [-6.82790493e-01],\n",
       "       [-6.28332158e-01],\n",
       "       [-7.10019661e-01],\n",
       "       [ 2.29386613e-01],\n",
       "       [-6.82790493e-01],\n",
       "       [-5.05800905e-01],\n",
       "       [ 1.12794914e+00],\n",
       "       [-6.55561326e-01],\n",
       "       [-7.10019661e-01],\n",
       "       [-5.46644656e-01],\n",
       "       [-4.92186322e-01],\n",
       "       [-6.41946742e-01],\n",
       "       [ 9.50959549e-01],\n",
       "       [ 1.10071997e+00],\n",
       "       [-6.28332158e-01],\n",
       "       [ 8.55657463e-01],\n",
       "       [ 3.00676168e+00],\n",
       "       [-4.37727987e-01],\n",
       "       [-5.73873824e-01],\n",
       "       [-8.05321746e-01],\n",
       "       [-9.68696751e-01],\n",
       "       [ 1.34578248e+00],\n",
       "       [-6.82790493e-01],\n",
       "       [ 5.15292871e-01],\n",
       "       [-3.83269652e-01],\n",
       "       [-6.69175910e-01],\n",
       "       [-2.33509232e-01],\n",
       "       [-1.92665481e-01],\n",
       "       [ 3.19736586e+00],\n",
       "       [-1.10484259e+00],\n",
       "       [ 8.28428295e-01],\n",
       "       [-1.79050897e-01],\n",
       "       [-9.00623832e-01],\n",
       "       [ 8.01199128e-01],\n",
       "       [-1.18653009e+00],\n",
       "       [-6.01102991e-01],\n",
       "       [-6.69175910e-01],\n",
       "       [-6.69175910e-01],\n",
       "       [-3.56040485e-01],\n",
       "       [ 2.72085543e+00],\n",
       "       [ 1.01903247e+00],\n",
       "       [ 2.43001197e-01],\n",
       "       [-7.50863412e-01],\n",
       "       [-4.92186322e-01],\n",
       "       [-8.18936330e-01],\n",
       "       [-2.06280064e-01],\n",
       "       [-8.18936330e-01],\n",
       "       [-3.28811318e-01],\n",
       "       [ 1.27770956e+00],\n",
       "       [ 9.78188716e-01],\n",
       "       [-7.37248828e-01],\n",
       "       [ 1.31855331e+00],\n",
       "       [-8.46165497e-01],\n",
       "       [-1.51821730e-01],\n",
       "       [-1.79050897e-01],\n",
       "       [ 1.98566791e+00],\n",
       "       [-8.46165497e-01]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_val = scaler_X.transform(X_val)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "\n",
    "y_train = scaler_y.fit_transform(y_train)\n",
    "y_val = scaler_y.transform(y_val)\n",
    "y_test = scaler_y.transform(y_test)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4e991c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a453bced",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DADOS_DE_ENTRADA = X_train.shape[1] \n",
    "NUM_DADOS_DE_SAIDA = 1  \n",
    "NEURONIOS_C1 = 5  \n",
    "NEURONIOS_C2 = 3  \n",
    "\n",
    "minha_mlp = MLP(\n",
    "    NUM_DADOS_DE_ENTRADA, NEURONIOS_C1, NEURONIOS_C2, NUM_DADOS_DE_SAIDA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "708e2cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAXA_DE_APRENDIZADO = 0.001\n",
    "otimizador = optim.SGD(minha_mlp.parameters(), lr=TAXA_DE_APRENDIZADO)\n",
    "\n",
    "\n",
    "fn_perda = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a65f71fe-ec17-4203-b899-13ef84544f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 0: perda treino = 1.7112, perda validação = 1.6829\n",
      "Época 1: perda treino = 1.7060, perda validação = 1.6784\n",
      "Época 2: perda treino = 1.7009, perda validação = 1.6738\n",
      "Época 3: perda treino = 1.6958, perda validação = 1.6693\n",
      "Época 4: perda treino = 1.6908, perda validação = 1.6648\n",
      "Época 5: perda treino = 1.6858, perda validação = 1.6604\n",
      "Época 6: perda treino = 1.6808, perda validação = 1.6560\n",
      "Época 7: perda treino = 1.6759, perda validação = 1.6516\n",
      "Época 8: perda treino = 1.6710, perda validação = 1.6472\n",
      "Época 9: perda treino = 1.6661, perda validação = 1.6429\n",
      "Época 10: perda treino = 1.6613, perda validação = 1.6387\n",
      "Época 11: perda treino = 1.6565, perda validação = 1.6344\n",
      "Época 12: perda treino = 1.6517, perda validação = 1.6302\n",
      "Época 13: perda treino = 1.6470, perda validação = 1.6261\n",
      "Época 14: perda treino = 1.6423, perda validação = 1.6219\n",
      "Época 15: perda treino = 1.6376, perda validação = 1.6178\n",
      "Época 16: perda treino = 1.6330, perda validação = 1.6137\n",
      "Época 17: perda treino = 1.6284, perda validação = 1.6097\n",
      "Época 18: perda treino = 1.6239, perda validação = 1.6057\n",
      "Época 19: perda treino = 1.6194, perda validação = 1.6017\n",
      "Época 20: perda treino = 1.6149, perda validação = 1.5978\n",
      "Época 21: perda treino = 1.6104, perda validação = 1.5938\n",
      "Época 22: perda treino = 1.6060, perda validação = 1.5899\n",
      "Época 23: perda treino = 1.6016, perda validação = 1.5861\n",
      "Época 24: perda treino = 1.5973, perda validação = 1.5823\n",
      "Época 25: perda treino = 1.5929, perda validação = 1.5785\n",
      "Época 26: perda treino = 1.5887, perda validação = 1.5747\n",
      "Época 27: perda treino = 1.5844, perda validação = 1.5710\n",
      "Época 28: perda treino = 1.5802, perda validação = 1.5673\n",
      "Época 29: perda treino = 1.5760, perda validação = 1.5636\n",
      "Época 30: perda treino = 1.5718, perda validação = 1.5599\n",
      "Época 31: perda treino = 1.5677, perda validação = 1.5563\n",
      "Época 32: perda treino = 1.5636, perda validação = 1.5527\n",
      "Época 33: perda treino = 1.5595, perda validação = 1.5492\n",
      "Época 34: perda treino = 1.5554, perda validação = 1.5456\n",
      "Época 35: perda treino = 1.5514, perda validação = 1.5421\n",
      "Época 36: perda treino = 1.5474, perda validação = 1.5386\n",
      "Época 37: perda treino = 1.5435, perda validação = 1.5352\n",
      "Época 38: perda treino = 1.5396, perda validação = 1.5318\n",
      "Época 39: perda treino = 1.5357, perda validação = 1.5284\n",
      "Época 40: perda treino = 1.5318, perda validação = 1.5250\n",
      "Época 41: perda treino = 1.5280, perda validação = 1.5216\n",
      "Época 42: perda treino = 1.5241, perda validação = 1.5183\n",
      "Época 43: perda treino = 1.5204, perda validação = 1.5150\n",
      "Época 44: perda treino = 1.5166, perda validação = 1.5118\n",
      "Época 45: perda treino = 1.5129, perda validação = 1.5085\n",
      "Época 46: perda treino = 1.5092, perda validação = 1.5053\n",
      "Época 47: perda treino = 1.5055, perda validação = 1.5021\n",
      "Época 48: perda treino = 1.5018, perda validação = 1.4989\n",
      "Época 49: perda treino = 1.4982, perda validação = 1.4958\n",
      "Época 50: perda treino = 1.4946, perda validação = 1.4927\n",
      "Época 51: perda treino = 1.4910, perda validação = 1.4896\n",
      "Época 52: perda treino = 1.4875, perda validação = 1.4865\n",
      "Época 53: perda treino = 1.4840, perda validação = 1.4835\n",
      "Época 54: perda treino = 1.4805, perda validação = 1.4805\n",
      "Época 55: perda treino = 1.4770, perda validação = 1.4775\n",
      "Época 56: perda treino = 1.4736, perda validação = 1.4745\n",
      "Época 57: perda treino = 1.4702, perda validação = 1.4715\n",
      "Época 58: perda treino = 1.4668, perda validação = 1.4686\n",
      "Época 59: perda treino = 1.4634, perda validação = 1.4657\n",
      "Época 60: perda treino = 1.4601, perda validação = 1.4628\n",
      "Época 61: perda treino = 1.4567, perda validação = 1.4600\n",
      "Época 62: perda treino = 1.4534, perda validação = 1.4571\n",
      "Época 63: perda treino = 1.4502, perda validação = 1.4543\n",
      "Época 64: perda treino = 1.4469, perda validação = 1.4515\n",
      "Época 65: perda treino = 1.4437, perda validação = 1.4488\n",
      "Época 66: perda treino = 1.4405, perda validação = 1.4460\n",
      "Época 67: perda treino = 1.4373, perda validação = 1.4433\n",
      "Época 68: perda treino = 1.4342, perda validação = 1.4406\n",
      "Época 69: perda treino = 1.4311, perda validação = 1.4379\n",
      "Época 70: perda treino = 1.4279, perda validação = 1.4352\n",
      "Época 71: perda treino = 1.4249, perda validação = 1.4326\n",
      "Época 72: perda treino = 1.4218, perda validação = 1.4300\n",
      "Época 73: perda treino = 1.4188, perda validação = 1.4274\n",
      "Época 74: perda treino = 1.4157, perda validação = 1.4248\n",
      "Época 75: perda treino = 1.4127, perda validação = 1.4222\n",
      "Época 76: perda treino = 1.4098, perda validação = 1.4197\n",
      "Época 77: perda treino = 1.4068, perda validação = 1.4172\n",
      "Época 78: perda treino = 1.4039, perda validação = 1.4147\n",
      "Época 79: perda treino = 1.4010, perda validação = 1.4122\n",
      "Época 80: perda treino = 1.3981, perda validação = 1.4097\n",
      "Época 81: perda treino = 1.3952, perda validação = 1.4073\n",
      "Época 82: perda treino = 1.3924, perda validação = 1.4049\n",
      "Época 83: perda treino = 1.3896, perda validação = 1.4025\n",
      "Época 84: perda treino = 1.3867, perda validação = 1.4001\n",
      "Época 85: perda treino = 1.3840, perda validação = 1.3977\n",
      "Época 86: perda treino = 1.3812, perda validação = 1.3954\n",
      "Época 87: perda treino = 1.3785, perda validação = 1.3931\n",
      "Época 88: perda treino = 1.3757, perda validação = 1.3908\n",
      "Época 89: perda treino = 1.3730, perda validação = 1.3885\n",
      "Época 90: perda treino = 1.3703, perda validação = 1.3862\n",
      "Época 91: perda treino = 1.3677, perda validação = 1.3839\n",
      "Época 92: perda treino = 1.3650, perda validação = 1.3817\n",
      "Época 93: perda treino = 1.3624, perda validação = 1.3795\n",
      "Época 94: perda treino = 1.3598, perda validação = 1.3773\n",
      "Época 95: perda treino = 1.3572, perda validação = 1.3751\n",
      "Época 96: perda treino = 1.3546, perda validação = 1.3729\n",
      "Época 97: perda treino = 1.3521, perda validação = 1.3708\n",
      "Época 98: perda treino = 1.3495, perda validação = 1.3687\n",
      "Época 99: perda treino = 1.3470, perda validação = 1.3665\n",
      "Época 100: perda treino = 1.3445, perda validação = 1.3645\n",
      "Época 101: perda treino = 1.3421, perda validação = 1.3624\n",
      "Época 102: perda treino = 1.3396, perda validação = 1.3603\n",
      "Época 103: perda treino = 1.3372, perda validação = 1.3583\n",
      "Época 104: perda treino = 1.3347, perda validação = 1.3562\n",
      "Época 105: perda treino = 1.3323, perda validação = 1.3542\n",
      "Época 106: perda treino = 1.3299, perda validação = 1.3522\n",
      "Época 107: perda treino = 1.3276, perda validação = 1.3502\n",
      "Época 108: perda treino = 1.3252, perda validação = 1.3483\n",
      "Época 109: perda treino = 1.3229, perda validação = 1.3463\n",
      "Época 110: perda treino = 1.3205, perda validação = 1.3444\n",
      "Época 111: perda treino = 1.3182, perda validação = 1.3424\n",
      "Época 112: perda treino = 1.3159, perda validação = 1.3405\n",
      "Época 113: perda treino = 1.3137, perda validação = 1.3386\n",
      "Época 114: perda treino = 1.3114, perda validação = 1.3368\n",
      "Época 115: perda treino = 1.3092, perda validação = 1.3349\n",
      "Época 116: perda treino = 1.3070, perda validação = 1.3331\n",
      "Época 117: perda treino = 1.3047, perda validação = 1.3312\n",
      "Época 118: perda treino = 1.3026, perda validação = 1.3294\n",
      "Época 119: perda treino = 1.3004, perda validação = 1.3276\n",
      "Época 120: perda treino = 1.2982, perda validação = 1.3258\n",
      "Época 121: perda treino = 1.2961, perda validação = 1.3240\n",
      "Época 122: perda treino = 1.2940, perda validação = 1.3223\n",
      "Época 123: perda treino = 1.2918, perda validação = 1.3205\n",
      "Época 124: perda treino = 1.2897, perda validação = 1.3188\n",
      "Época 125: perda treino = 1.2877, perda validação = 1.3171\n",
      "Época 126: perda treino = 1.2856, perda validação = 1.3154\n",
      "Época 127: perda treino = 1.2835, perda validação = 1.3137\n",
      "Época 128: perda treino = 1.2815, perda validação = 1.3120\n",
      "Época 129: perda treino = 1.2795, perda validação = 1.3103\n",
      "Época 130: perda treino = 1.2775, perda validação = 1.3087\n",
      "Época 131: perda treino = 1.2755, perda validação = 1.3071\n",
      "Época 132: perda treino = 1.2735, perda validação = 1.3054\n",
      "Época 133: perda treino = 1.2715, perda validação = 1.3038\n",
      "Época 134: perda treino = 1.2696, perda validação = 1.3022\n",
      "Época 135: perda treino = 1.2676, perda validação = 1.3006\n",
      "Época 136: perda treino = 1.2657, perda validação = 1.2991\n",
      "Época 137: perda treino = 1.2638, perda validação = 1.2975\n",
      "Época 138: perda treino = 1.2619, perda validação = 1.2960\n",
      "Época 139: perda treino = 1.2600, perda validação = 1.2944\n",
      "Época 140: perda treino = 1.2582, perda validação = 1.2929\n",
      "Época 141: perda treino = 1.2563, perda validação = 1.2914\n",
      "Época 142: perda treino = 1.2545, perda validação = 1.2899\n",
      "Época 143: perda treino = 1.2526, perda validação = 1.2884\n",
      "Época 144: perda treino = 1.2508, perda validação = 1.2869\n",
      "Época 145: perda treino = 1.2490, perda validação = 1.2855\n",
      "Época 146: perda treino = 1.2472, perda validação = 1.2840\n",
      "Época 147: perda treino = 1.2455, perda validação = 1.2826\n",
      "Época 148: perda treino = 1.2437, perda validação = 1.2811\n",
      "Época 149: perda treino = 1.2419, perda validação = 1.2797\n",
      "Época 150: perda treino = 1.2402, perda validação = 1.2783\n",
      "Época 151: perda treino = 1.2385, perda validação = 1.2769\n",
      "Época 152: perda treino = 1.2368, perda validação = 1.2755\n",
      "Época 153: perda treino = 1.2351, perda validação = 1.2742\n",
      "Época 154: perda treino = 1.2334, perda validação = 1.2728\n",
      "Época 155: perda treino = 1.2317, perda validação = 1.2715\n",
      "Época 156: perda treino = 1.2300, perda validação = 1.2701\n",
      "Época 157: perda treino = 1.2284, perda validação = 1.2688\n",
      "Época 158: perda treino = 1.2267, perda validação = 1.2675\n",
      "Época 159: perda treino = 1.2251, perda validação = 1.2662\n",
      "Época 160: perda treino = 1.2235, perda validação = 1.2649\n",
      "Época 161: perda treino = 1.2219, perda validação = 1.2636\n",
      "Época 162: perda treino = 1.2203, perda validação = 1.2623\n",
      "Época 163: perda treino = 1.2187, perda validação = 1.2610\n",
      "Época 164: perda treino = 1.2171, perda validação = 1.2598\n",
      "Época 165: perda treino = 1.2156, perda validação = 1.2585\n",
      "Época 166: perda treino = 1.2140, perda validação = 1.2573\n",
      "Época 167: perda treino = 1.2125, perda validação = 1.2561\n",
      "Época 168: perda treino = 1.2110, perda validação = 1.2549\n",
      "Época 169: perda treino = 1.2095, perda validação = 1.2537\n",
      "Época 170: perda treino = 1.2080, perda validação = 1.2525\n",
      "Época 171: perda treino = 1.2065, perda validação = 1.2513\n",
      "Época 172: perda treino = 1.2050, perda validação = 1.2501\n",
      "Época 173: perda treino = 1.2035, perda validação = 1.2489\n",
      "Época 174: perda treino = 1.2020, perda validação = 1.2478\n",
      "Época 175: perda treino = 1.2006, perda validação = 1.2466\n",
      "Época 176: perda treino = 1.1992, perda validação = 1.2455\n",
      "Época 177: perda treino = 1.1977, perda validação = 1.2444\n",
      "Época 178: perda treino = 1.1963, perda validação = 1.2433\n",
      "Época 179: perda treino = 1.1949, perda validação = 1.2421\n",
      "Época 180: perda treino = 1.1935, perda validação = 1.2410\n",
      "Época 181: perda treino = 1.1921, perda validação = 1.2400\n",
      "Época 182: perda treino = 1.1907, perda validação = 1.2389\n",
      "Época 183: perda treino = 1.1894, perda validação = 1.2378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 184: perda treino = 1.1880, perda validação = 1.2367\n",
      "Época 185: perda treino = 1.1867, perda validação = 1.2357\n",
      "Época 186: perda treino = 1.1853, perda validação = 1.2346\n",
      "Época 187: perda treino = 1.1840, perda validação = 1.2336\n",
      "Época 188: perda treino = 1.1827, perda validação = 1.2326\n",
      "Época 189: perda treino = 1.1813, perda validação = 1.2315\n",
      "Época 190: perda treino = 1.1800, perda validação = 1.2305\n",
      "Época 191: perda treino = 1.1788, perda validação = 1.2295\n",
      "Época 192: perda treino = 1.1775, perda validação = 1.2285\n",
      "Época 193: perda treino = 1.1762, perda validação = 1.2275\n",
      "Época 194: perda treino = 1.1749, perda validação = 1.2265\n",
      "Época 195: perda treino = 1.1737, perda validação = 1.2256\n",
      "Época 196: perda treino = 1.1724, perda validação = 1.2246\n",
      "Época 197: perda treino = 1.1712, perda validação = 1.2236\n",
      "Época 198: perda treino = 1.1700, perda validação = 1.2227\n",
      "Época 199: perda treino = 1.1687, perda validação = 1.2218\n",
      "Época 200: perda treino = 1.1675, perda validação = 1.2208\n",
      "Época 201: perda treino = 1.1663, perda validação = 1.2199\n",
      "Época 202: perda treino = 1.1651, perda validação = 1.2190\n",
      "Época 203: perda treino = 1.1639, perda validação = 1.2181\n",
      "Época 204: perda treino = 1.1628, perda validação = 1.2172\n",
      "Época 205: perda treino = 1.1616, perda validação = 1.2163\n",
      "Época 206: perda treino = 1.1604, perda validação = 1.2154\n",
      "Época 207: perda treino = 1.1593, perda validação = 1.2145\n",
      "Época 208: perda treino = 1.1581, perda validação = 1.2136\n",
      "Época 209: perda treino = 1.1570, perda validação = 1.2127\n",
      "Época 210: perda treino = 1.1559, perda validação = 1.2119\n",
      "Época 211: perda treino = 1.1548, perda validação = 1.2110\n",
      "Época 212: perda treino = 1.1536, perda validação = 1.2102\n",
      "Época 213: perda treino = 1.1525, perda validação = 1.2094\n",
      "Época 214: perda treino = 1.1515, perda validação = 1.2085\n",
      "Época 215: perda treino = 1.1504, perda validação = 1.2077\n",
      "Época 216: perda treino = 1.1493, perda validação = 1.2069\n",
      "Época 217: perda treino = 1.1482, perda validação = 1.2061\n",
      "Época 218: perda treino = 1.1471, perda validação = 1.2053\n",
      "Época 219: perda treino = 1.1461, perda validação = 1.2045\n",
      "Época 220: perda treino = 1.1450, perda validação = 1.2037\n",
      "Época 221: perda treino = 1.1440, perda validação = 1.2029\n",
      "Época 222: perda treino = 1.1430, perda validação = 1.2021\n",
      "Época 223: perda treino = 1.1419, perda validação = 1.2013\n",
      "Época 224: perda treino = 1.1409, perda validação = 1.2006\n",
      "Época 225: perda treino = 1.1399, perda validação = 1.1998\n",
      "Época 226: perda treino = 1.1389, perda validação = 1.1991\n",
      "Época 227: perda treino = 1.1379, perda validação = 1.1983\n",
      "Época 228: perda treino = 1.1369, perda validação = 1.1976\n",
      "Época 229: perda treino = 1.1359, perda validação = 1.1968\n",
      "Época 230: perda treino = 1.1350, perda validação = 1.1961\n",
      "Época 231: perda treino = 1.1340, perda validação = 1.1954\n",
      "Época 232: perda treino = 1.1330, perda validação = 1.1947\n",
      "Época 233: perda treino = 1.1321, perda validação = 1.1940\n",
      "Época 234: perda treino = 1.1311, perda validação = 1.1933\n",
      "Época 235: perda treino = 1.1302, perda validação = 1.1926\n",
      "Época 236: perda treino = 1.1292, perda validação = 1.1919\n",
      "Época 237: perda treino = 1.1283, perda validação = 1.1912\n",
      "Época 238: perda treino = 1.1274, perda validação = 1.1905\n",
      "Época 239: perda treino = 1.1265, perda validação = 1.1898\n",
      "Época 240: perda treino = 1.1256, perda validação = 1.1892\n",
      "Época 241: perda treino = 1.1247, perda validação = 1.1885\n",
      "Época 242: perda treino = 1.1238, perda validação = 1.1879\n",
      "Época 243: perda treino = 1.1229, perda validação = 1.1872\n",
      "Época 244: perda treino = 1.1220, perda validação = 1.1866\n",
      "Época 245: perda treino = 1.1211, perda validação = 1.1859\n",
      "Época 246: perda treino = 1.1203, perda validação = 1.1853\n",
      "Época 247: perda treino = 1.1194, perda validação = 1.1846\n",
      "Época 248: perda treino = 1.1185, perda validação = 1.1840\n",
      "Época 249: perda treino = 1.1177, perda validação = 1.1834\n",
      "Época 250: perda treino = 1.1168, perda validação = 1.1828\n",
      "Época 251: perda treino = 1.1160, perda validação = 1.1822\n",
      "Época 252: perda treino = 1.1152, perda validação = 1.1816\n",
      "Época 253: perda treino = 1.1143, perda validação = 1.1810\n",
      "Época 254: perda treino = 1.1135, perda validação = 1.1804\n",
      "Época 255: perda treino = 1.1127, perda validação = 1.1798\n",
      "Época 256: perda treino = 1.1119, perda validação = 1.1792\n",
      "Época 257: perda treino = 1.1111, perda validação = 1.1786\n",
      "Época 258: perda treino = 1.1103, perda validação = 1.1781\n",
      "Época 259: perda treino = 1.1095, perda validação = 1.1775\n",
      "Época 260: perda treino = 1.1087, perda validação = 1.1769\n",
      "Época 261: perda treino = 1.1079, perda validação = 1.1764\n",
      "Época 262: perda treino = 1.1071, perda validação = 1.1758\n",
      "Época 263: perda treino = 1.1064, perda validação = 1.1753\n",
      "Época 264: perda treino = 1.1056, perda validação = 1.1747\n",
      "Época 265: perda treino = 1.1049, perda validação = 1.1742\n",
      "Época 266: perda treino = 1.1041, perda validação = 1.1737\n",
      "Época 267: perda treino = 1.1034, perda validação = 1.1731\n",
      "Época 268: perda treino = 1.1026, perda validação = 1.1726\n",
      "Época 269: perda treino = 1.1019, perda validação = 1.1721\n",
      "Época 270: perda treino = 1.1011, perda validação = 1.1716\n",
      "Época 271: perda treino = 1.1004, perda validação = 1.1710\n",
      "Época 272: perda treino = 1.0997, perda validação = 1.1705\n",
      "Época 273: perda treino = 1.0990, perda validação = 1.1700\n",
      "Época 274: perda treino = 1.0983, perda validação = 1.1695\n",
      "Época 275: perda treino = 1.0976, perda validação = 1.1690\n",
      "Época 276: perda treino = 1.0969, perda validação = 1.1685\n",
      "Época 277: perda treino = 1.0962, perda validação = 1.1681\n",
      "Época 278: perda treino = 1.0955, perda validação = 1.1676\n",
      "Época 279: perda treino = 1.0948, perda validação = 1.1671\n",
      "Época 280: perda treino = 1.0941, perda validação = 1.1666\n",
      "Época 281: perda treino = 1.0934, perda validação = 1.1662\n",
      "Época 282: perda treino = 1.0927, perda validação = 1.1657\n",
      "Época 283: perda treino = 1.0921, perda validação = 1.1652\n",
      "Época 284: perda treino = 1.0914, perda validação = 1.1648\n",
      "Época 285: perda treino = 1.0908, perda validação = 1.1643\n",
      "Época 286: perda treino = 1.0901, perda validação = 1.1639\n",
      "Época 287: perda treino = 1.0895, perda validação = 1.1634\n",
      "Época 288: perda treino = 1.0888, perda validação = 1.1630\n",
      "Época 289: perda treino = 1.0882, perda validação = 1.1625\n",
      "Época 290: perda treino = 1.0875, perda validação = 1.1621\n",
      "Época 291: perda treino = 1.0869, perda validação = 1.1617\n",
      "Época 292: perda treino = 1.0863, perda validação = 1.1613\n",
      "Época 293: perda treino = 1.0857, perda validação = 1.1608\n",
      "Época 294: perda treino = 1.0850, perda validação = 1.1604\n",
      "Época 295: perda treino = 1.0844, perda validação = 1.1600\n",
      "Época 296: perda treino = 1.0838, perda validação = 1.1596\n",
      "Época 297: perda treino = 1.0832, perda validação = 1.1592\n",
      "Época 298: perda treino = 1.0826, perda validação = 1.1588\n",
      "Época 299: perda treino = 1.0820, perda validação = 1.1584\n",
      "Época 300: perda treino = 1.0814, perda validação = 1.1580\n",
      "Época 301: perda treino = 1.0809, perda validação = 1.1576\n",
      "Época 302: perda treino = 1.0803, perda validação = 1.1572\n",
      "Época 303: perda treino = 1.0797, perda validação = 1.1568\n",
      "Época 304: perda treino = 1.0791, perda validação = 1.1564\n",
      "Época 305: perda treino = 1.0786, perda validação = 1.1561\n",
      "Época 306: perda treino = 1.0780, perda validação = 1.1557\n",
      "Época 307: perda treino = 1.0774, perda validação = 1.1553\n",
      "Época 308: perda treino = 1.0769, perda validação = 1.1549\n",
      "Época 309: perda treino = 1.0763, perda validação = 1.1546\n",
      "Época 310: perda treino = 1.0758, perda validação = 1.1542\n",
      "Época 311: perda treino = 1.0752, perda validação = 1.1538\n",
      "Época 312: perda treino = 1.0747, perda validação = 1.1535\n",
      "Época 313: perda treino = 1.0741, perda validação = 1.1531\n",
      "Época 314: perda treino = 1.0736, perda validação = 1.1528\n",
      "Época 315: perda treino = 1.0731, perda validação = 1.1524\n",
      "Época 316: perda treino = 1.0725, perda validação = 1.1521\n",
      "Época 317: perda treino = 1.0720, perda validação = 1.1518\n",
      "Época 318: perda treino = 1.0715, perda validação = 1.1514\n",
      "Época 319: perda treino = 1.0710, perda validação = 1.1511\n",
      "Época 320: perda treino = 1.0705, perda validação = 1.1508\n",
      "Época 321: perda treino = 1.0700, perda validação = 1.1504\n",
      "Época 322: perda treino = 1.0695, perda validação = 1.1501\n",
      "Época 323: perda treino = 1.0690, perda validação = 1.1498\n",
      "Época 324: perda treino = 1.0685, perda validação = 1.1495\n",
      "Época 325: perda treino = 1.0680, perda validação = 1.1491\n",
      "Época 326: perda treino = 1.0675, perda validação = 1.1488\n",
      "Época 327: perda treino = 1.0670, perda validação = 1.1485\n",
      "Época 328: perda treino = 1.0665, perda validação = 1.1482\n",
      "Época 329: perda treino = 1.0660, perda validação = 1.1479\n",
      "Época 330: perda treino = 1.0656, perda validação = 1.1476\n",
      "Época 331: perda treino = 1.0651, perda validação = 1.1473\n",
      "Época 332: perda treino = 1.0646, perda validação = 1.1470\n",
      "Época 333: perda treino = 1.0642, perda validação = 1.1467\n",
      "Época 334: perda treino = 1.0637, perda validação = 1.1464\n",
      "Época 335: perda treino = 1.0632, perda validação = 1.1461\n",
      "Época 336: perda treino = 1.0628, perda validação = 1.1458\n",
      "Época 337: perda treino = 1.0623, perda validação = 1.1456\n",
      "Época 338: perda treino = 1.0619, perda validação = 1.1453\n",
      "Época 339: perda treino = 1.0614, perda validação = 1.1450\n",
      "Época 340: perda treino = 1.0610, perda validação = 1.1447\n",
      "Época 341: perda treino = 1.0605, perda validação = 1.1445\n",
      "Época 342: perda treino = 1.0601, perda validação = 1.1442\n",
      "Época 343: perda treino = 1.0597, perda validação = 1.1439\n",
      "Época 344: perda treino = 1.0592, perda validação = 1.1437\n",
      "Época 345: perda treino = 1.0588, perda validação = 1.1434\n",
      "Época 346: perda treino = 1.0584, perda validação = 1.1431\n",
      "Época 347: perda treino = 1.0580, perda validação = 1.1429\n",
      "Época 348: perda treino = 1.0576, perda validação = 1.1426\n",
      "Época 349: perda treino = 1.0571, perda validação = 1.1424\n",
      "Época 350: perda treino = 1.0567, perda validação = 1.1421\n",
      "Época 351: perda treino = 1.0563, perda validação = 1.1419\n",
      "Época 352: perda treino = 1.0559, perda validação = 1.1416\n",
      "Época 353: perda treino = 1.0555, perda validação = 1.1414\n",
      "Época 354: perda treino = 1.0551, perda validação = 1.1411\n",
      "Época 355: perda treino = 1.0547, perda validação = 1.1409\n",
      "Época 356: perda treino = 1.0543, perda validação = 1.1407\n",
      "Época 357: perda treino = 1.0539, perda validação = 1.1404\n",
      "Época 358: perda treino = 1.0535, perda validação = 1.1402\n",
      "Época 359: perda treino = 1.0531, perda validação = 1.1400\n",
      "Época 360: perda treino = 1.0528, perda validação = 1.1397\n",
      "Época 361: perda treino = 1.0524, perda validação = 1.1395\n",
      "Época 362: perda treino = 1.0520, perda validação = 1.1393\n",
      "Época 363: perda treino = 1.0516, perda validação = 1.1391\n",
      "Época 364: perda treino = 1.0513, perda validação = 1.1388\n",
      "Época 365: perda treino = 1.0509, perda validação = 1.1386\n",
      "Época 366: perda treino = 1.0505, perda validação = 1.1384\n",
      "Época 367: perda treino = 1.0501, perda validação = 1.1382\n",
      "Época 368: perda treino = 1.0498, perda validação = 1.1380\n",
      "Época 369: perda treino = 1.0494, perda validação = 1.1378\n",
      "Época 370: perda treino = 1.0491, perda validação = 1.1376\n",
      "Época 371: perda treino = 1.0487, perda validação = 1.1374\n",
      "Época 372: perda treino = 1.0484, perda validação = 1.1372\n",
      "Época 373: perda treino = 1.0480, perda validação = 1.1370\n",
      "Época 374: perda treino = 1.0477, perda validação = 1.1368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 375: perda treino = 1.0473, perda validação = 1.1366\n",
      "Época 376: perda treino = 1.0470, perda validação = 1.1364\n",
      "Época 377: perda treino = 1.0466, perda validação = 1.1362\n",
      "Época 378: perda treino = 1.0463, perda validação = 1.1360\n",
      "Época 379: perda treino = 1.0460, perda validação = 1.1358\n",
      "Época 380: perda treino = 1.0456, perda validação = 1.1356\n",
      "Época 381: perda treino = 1.0453, perda validação = 1.1354\n",
      "Época 382: perda treino = 1.0450, perda validação = 1.1352\n",
      "Época 383: perda treino = 1.0446, perda validação = 1.1351\n",
      "Época 384: perda treino = 1.0443, perda validação = 1.1349\n",
      "Época 385: perda treino = 1.0440, perda validação = 1.1347\n",
      "Época 386: perda treino = 1.0437, perda validação = 1.1345\n",
      "Época 387: perda treino = 1.0434, perda validação = 1.1344\n",
      "Época 388: perda treino = 1.0431, perda validação = 1.1342\n",
      "Época 389: perda treino = 1.0427, perda validação = 1.1340\n",
      "Época 390: perda treino = 1.0424, perda validação = 1.1338\n",
      "Época 391: perda treino = 1.0421, perda validação = 1.1337\n",
      "Época 392: perda treino = 1.0418, perda validação = 1.1335\n",
      "Época 393: perda treino = 1.0415, perda validação = 1.1333\n",
      "Época 394: perda treino = 1.0412, perda validação = 1.1332\n",
      "Época 395: perda treino = 1.0409, perda validação = 1.1330\n",
      "Época 396: perda treino = 1.0406, perda validação = 1.1329\n",
      "Época 397: perda treino = 1.0403, perda validação = 1.1327\n",
      "Época 398: perda treino = 1.0400, perda validação = 1.1325\n",
      "Época 399: perda treino = 1.0397, perda validação = 1.1324\n",
      "Época 400: perda treino = 1.0395, perda validação = 1.1322\n",
      "Época 401: perda treino = 1.0392, perda validação = 1.1321\n",
      "Época 402: perda treino = 1.0389, perda validação = 1.1319\n",
      "Época 403: perda treino = 1.0386, perda validação = 1.1318\n",
      "Época 404: perda treino = 1.0383, perda validação = 1.1316\n",
      "Época 405: perda treino = 1.0380, perda validação = 1.1315\n",
      "Época 406: perda treino = 1.0378, perda validação = 1.1314\n",
      "Época 407: perda treino = 1.0375, perda validação = 1.1312\n",
      "Época 408: perda treino = 1.0372, perda validação = 1.1311\n",
      "Época 409: perda treino = 1.0370, perda validação = 1.1309\n",
      "Época 410: perda treino = 1.0367, perda validação = 1.1308\n",
      "Época 411: perda treino = 1.0364, perda validação = 1.1307\n",
      "Época 412: perda treino = 1.0362, perda validação = 1.1305\n",
      "Época 413: perda treino = 1.0359, perda validação = 1.1304\n",
      "Época 414: perda treino = 1.0356, perda validação = 1.1303\n",
      "Época 415: perda treino = 1.0354, perda validação = 1.1301\n",
      "Época 416: perda treino = 1.0351, perda validação = 1.1300\n",
      "Época 417: perda treino = 1.0349, perda validação = 1.1299\n",
      "Época 418: perda treino = 1.0346, perda validação = 1.1297\n",
      "Época 419: perda treino = 1.0344, perda validação = 1.1296\n",
      "Época 420: perda treino = 1.0341, perda validação = 1.1295\n",
      "Época 421: perda treino = 1.0339, perda validação = 1.1294\n",
      "Época 422: perda treino = 1.0336, perda validação = 1.1293\n",
      "Época 423: perda treino = 1.0334, perda validação = 1.1291\n",
      "Época 424: perda treino = 1.0331, perda validação = 1.1290\n",
      "Época 425: perda treino = 1.0329, perda validação = 1.1289\n",
      "Época 426: perda treino = 1.0326, perda validação = 1.1288\n",
      "Época 427: perda treino = 1.0324, perda validação = 1.1287\n",
      "Época 428: perda treino = 1.0322, perda validação = 1.1286\n",
      "Época 429: perda treino = 1.0319, perda validação = 1.1284\n",
      "Época 430: perda treino = 1.0317, perda validação = 1.1283\n",
      "Época 431: perda treino = 1.0315, perda validação = 1.1282\n",
      "Época 432: perda treino = 1.0312, perda validação = 1.1281\n",
      "Época 433: perda treino = 1.0310, perda validação = 1.1280\n",
      "Época 434: perda treino = 1.0308, perda validação = 1.1279\n",
      "Época 435: perda treino = 1.0306, perda validação = 1.1278\n",
      "Época 436: perda treino = 1.0303, perda validação = 1.1277\n",
      "Época 437: perda treino = 1.0301, perda validação = 1.1276\n",
      "Época 438: perda treino = 1.0299, perda validação = 1.1275\n",
      "Época 439: perda treino = 1.0297, perda validação = 1.1274\n",
      "Época 440: perda treino = 1.0295, perda validação = 1.1273\n",
      "Época 441: perda treino = 1.0293, perda validação = 1.1272\n",
      "Época 442: perda treino = 1.0290, perda validação = 1.1271\n",
      "Época 443: perda treino = 1.0288, perda validação = 1.1270\n",
      "Época 444: perda treino = 1.0286, perda validação = 1.1269\n",
      "Época 445: perda treino = 1.0284, perda validação = 1.1268\n",
      "Época 446: perda treino = 1.0282, perda validação = 1.1267\n",
      "Época 447: perda treino = 1.0280, perda validação = 1.1266\n",
      "Época 448: perda treino = 1.0278, perda validação = 1.1265\n",
      "Época 449: perda treino = 1.0276, perda validação = 1.1264\n",
      "Época 450: perda treino = 1.0274, perda validação = 1.1264\n",
      "Época 451: perda treino = 1.0272, perda validação = 1.1263\n",
      "Época 452: perda treino = 1.0270, perda validação = 1.1262\n",
      "Época 453: perda treino = 1.0268, perda validação = 1.1261\n",
      "Parada antecipada na época 453 com perda da validação = 1.1261\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCAS = 1000\n",
    "paciencia = 10\n",
    "min_delta = 0.001\n",
    "melhor_loss = float(\"inf\")\n",
    "contador_paciencia = 0\n",
    "\n",
    "minha_mlp.train()\n",
    "\n",
    "for epoca in range(NUM_EPOCAS):\n",
    "    y_pred = minha_mlp(X_train_tensor)\n",
    "\n",
    "    otimizador.zero_grad()\n",
    "\n",
    "    loss = fn_perda(y_pred, y_train_tensor)\n",
    "    \n",
    "    y_pred_val = minha_mlp(X_val_tensor)\n",
    "    loss_val = fn_perda(y_pred_val, y_val_tensor)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    otimizador.step()\n",
    "    \n",
    "    print(f\"Época {epoca}: perda treino = {loss.item():.4f}, perda validação = {loss_val.item():.4f}\")\n",
    "\n",
    "    # === EARLY STOPPING COM BASE NA VALIDAÇÃO ===\n",
    "    if loss_val.item() < melhor_loss - min_delta:\n",
    "        melhor_loss = loss_val.item()\n",
    "        contador_paciencia = 0\n",
    "    else:\n",
    "        contador_paciencia += 1\n",
    "        if contador_paciencia >= paciencia:\n",
    "            print(f\"Parada antecipada na época {epoca} com perda da validação = {loss_val.item():.4f}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3e6fa4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (camadas): Sequential(\n",
       "    (0): Linear(in_features=6, out_features=5, bias=True)\n",
       "    (1): Sigmoid()\n",
       "    (2): Linear(in_features=5, out_features=3, bias=True)\n",
       "    (3): Sigmoid()\n",
       "    (4): Linear(in_features=3, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minha_mlp.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1f08d37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = minha_mlp(X_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6ef383f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1629],\n",
       "        [-0.1460],\n",
       "        [-0.1595],\n",
       "        [-0.1598],\n",
       "        [-0.1485],\n",
       "        [-0.1815],\n",
       "        [-0.1772],\n",
       "        [-0.1615],\n",
       "        [-0.1543],\n",
       "        [-0.1720],\n",
       "        [-0.1610],\n",
       "        [-0.1515],\n",
       "        [-0.1798],\n",
       "        [-0.1572],\n",
       "        [-0.1605],\n",
       "        [-0.1547],\n",
       "        [-0.1667],\n",
       "        [-0.1662],\n",
       "        [-0.1736],\n",
       "        [-0.1600],\n",
       "        [-0.1727],\n",
       "        [-0.1787],\n",
       "        [-0.1743],\n",
       "        [-0.1646],\n",
       "        [-0.1693],\n",
       "        [-0.1440],\n",
       "        [-0.1721],\n",
       "        [-0.1708],\n",
       "        [-0.1690],\n",
       "        [-0.1518],\n",
       "        [-0.1443],\n",
       "        [-0.1709],\n",
       "        [-0.1653],\n",
       "        [-0.1817],\n",
       "        [-0.1598],\n",
       "        [-0.1673],\n",
       "        [-0.1645],\n",
       "        [-0.1630],\n",
       "        [-0.1472],\n",
       "        [-0.1419],\n",
       "        [-0.1709],\n",
       "        [-0.1559],\n",
       "        [-0.1522],\n",
       "        [-0.1660],\n",
       "        [-0.1716],\n",
       "        [-0.1634],\n",
       "        [-0.1313],\n",
       "        [-0.1813],\n",
       "        [-0.1575],\n",
       "        [-0.1507],\n",
       "        [-0.1550],\n",
       "        [-0.1696],\n",
       "        [-0.1787],\n",
       "        [-0.1673],\n",
       "        [-0.1599],\n",
       "        [-0.1664],\n",
       "        [-0.1696],\n",
       "        [-0.1946],\n",
       "        [-0.1551],\n",
       "        [-0.1703],\n",
       "        [-0.1613],\n",
       "        [-0.1730],\n",
       "        [-0.1838],\n",
       "        [-0.1892],\n",
       "        [-0.1699],\n",
       "        [-0.1433],\n",
       "        [-0.1716],\n",
       "        [-0.1719],\n",
       "        [-0.1676],\n",
       "        [-0.1634],\n",
       "        [-0.1510],\n",
       "        [-0.1654],\n",
       "        [-0.1701],\n",
       "        [-0.1564],\n",
       "        [-0.1735],\n",
       "        [-0.1484],\n",
       "        [-0.1643],\n",
       "        [-0.1770],\n",
       "        [-0.1491],\n",
       "        [-0.1659],\n",
       "        [-0.1861],\n",
       "        [-0.1514],\n",
       "        [-0.1801],\n",
       "        [-0.1710],\n",
       "        [-0.1491],\n",
       "        [-0.1802],\n",
       "        [-0.1626],\n",
       "        [-0.1684],\n",
       "        [-0.1789],\n",
       "        [-0.1797],\n",
       "        [-0.1690],\n",
       "        [-0.1509],\n",
       "        [-0.1596],\n",
       "        [-0.1806],\n",
       "        [-0.1643],\n",
       "        [-0.1798],\n",
       "        [-0.1702],\n",
       "        [-0.1790],\n",
       "        [-0.1741],\n",
       "        [-0.1507],\n",
       "        [-0.1688],\n",
       "        [-0.1641],\n",
       "        [-0.1726],\n",
       "        [-0.1759],\n",
       "        [-0.1658],\n",
       "        [-0.1663],\n",
       "        [-0.1708],\n",
       "        [-0.1715],\n",
       "        [-0.1576],\n",
       "        [-0.1640],\n",
       "        [-0.1660],\n",
       "        [-0.1722],\n",
       "        [-0.1580],\n",
       "        [-0.1641],\n",
       "        [-0.1732],\n",
       "        [-0.1804],\n",
       "        [-0.1692],\n",
       "        [-0.1679],\n",
       "        [-0.1569],\n",
       "        [-0.1719],\n",
       "        [-0.1606],\n",
       "        [-0.1790],\n",
       "        [-0.1704],\n",
       "        [-0.1634],\n",
       "        [-0.1548],\n",
       "        [-0.1570],\n",
       "        [-0.1660],\n",
       "        [-0.1579],\n",
       "        [-0.1778],\n",
       "        [-0.1706],\n",
       "        [-0.1478],\n",
       "        [-0.1686]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4d52fe37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14631081489808\n"
     ]
    }
   ],
   "source": [
    "RMSE = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3586a91e",
   "metadata": {},
   "source": [
    "- [medium](https://cyborgcodes.medium.com/what-is-early-stopping-in-deep-learning-eeb1e710a3cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac08dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilumpy",
   "language": "python",
   "name": "ilumpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
